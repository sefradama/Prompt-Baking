{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"/v2/external/notebooks/gpu.ipynb","timestamp":1759308377289}],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13235804,"sourceType":"datasetVersion","datasetId":8387482},{"sourceId":363131,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":301511,"modelId":322000}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%rm -rf /kaggle/working/*\n%cp -r /kaggle/input/qwen3-prompt-baking/* /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-02T04:42:24.173181Z","iopub.execute_input":"2025-10-02T04:42:24.173569Z","iopub.status.idle":"2025-10-02T04:42:24.435251Z","shell.execute_reply.started":"2025-10-02T04:42:24.173538Z","shell.execute_reply":"2025-10-02T04:42:24.434167Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"%cd /kaggle/working/\n!python generate_data.py \\\n  --num_questions 88 \\\n  --traj_out_file data/traj_chat.jsonl \\\n  --val_out_file data/traj_val.jsonl \\\n  --num_sequences_per_question 25 \\\n  --max_sequence_length 300 \\\n  --min_sequence_length 100 \\\n  --temperature 2.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9KT9X8e-xe6","executionInfo":{"status":"ok","timestamp":1759317845691,"user_tz":-570,"elapsed":1794977,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}},"outputId":"2d1bbc22-769e-4869-e754-38a711e81b6c","trusted":true,"execution":{"iopub.status.busy":"2025-10-02T04:42:46.693319Z","iopub.execute_input":"2025-10-02T04:42:46.693697Z","iopub.status.idle":"2025-10-02T04:44:25.090944Z","shell.execute_reply.started":"2025-10-02T04:42:46.693666Z","shell.execute_reply":"2025-10-02T04:44:25.088066Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nGenerating train split: 88 examples [00:00, 27324.46 examples/s]\nLength of train_dataset:  88\nGenerating 88 questions for both training and validation files\n2025-10-02 04:43:32.632524: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759380212.942679      90 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759380213.033612      90 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nLoading checkpoint shards: 100%|██████████████████| 2/2 [00:26<00:00, 13.07s/it]\nTraceback (most recent call last):\n  File \"/kaggle/working/generate_data.py\", line 89, in <module>\n    model = model.cuda()\n            ^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 3807, in cuda\n    return super().cuda(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1053, in cuda\n    return self._apply(lambda t: t.cuda(device))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 903, in _apply\n    module._apply(fn)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 930, in _apply\n    param_applied = fn(param)\n                    ^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1053, in <lambda>\n    return self._apply(lambda t: t.cuda(device))\n                                 ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py\", line 319, in _lazy_init\n    torch._C._cuda_init()\nRuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"%cd /kaggle/working/\n!python train_loop.py","metadata":{"id":"VOHIEBw0MLyf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759318238905,"user_tz":-570,"elapsed":43305,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}},"outputId":"092a9782-3727-4623-a54b-a7a50678d9d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n","2025-10-01 11:30:05.142995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Arguments saved to results/traj_chat/args.json\n","Generating train split: 2200 examples [00:00, 4542.03 examples/s]\n","Generating train split: 2200 examples [00:00, 6107.25 examples/s]\n","`torch_dtype` is deprecated! Use `dtype` instead!\n","Loading checkpoint shards: 100% 2/2 [00:15<00:00,  7.84s/it]\n","Device set to use cuda:0\n","unprompted model parameter stats:\n","trainable params: 12,845,056 || all params: 1,733,420,032 || trainable%: 0.7410\n","  0% 0/220 [00:04<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/training/train_loop.py\", line 310, in <module>\n","    train_kls = do_epoch(peft_model, tokenizer,\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/training/train_loop.py\", line 218, in do_epoch\n","    unprompted_logits_ = peft_model(input_ids_nosys).logits\n","                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 1850, in forward\n","    return self.base_model(\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n","    return self.model.forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 940, in wrapper\n","    output = func(self, *args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 480, in forward\n","    outputs: BaseModelOutputWithPast = self.model(\n","                                       ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 1064, in wrapper\n","    outputs = func(self, *args, **kwargs)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 410, in forward\n","    hidden_states = decoder_layer(\n","                    ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n","    return super().__call__(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 260, in forward\n","    hidden_states, _ = self.self_attn(\n","                       ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 200, in forward\n","    query_states = self.q_norm(self.q_proj(hidden_states).view(hidden_shape)).transpose(1, 2)\n","                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py\", line 771, in forward\n","    result = result + lora_B(lora_A(dropout(x))) * scaling\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","    return F.linear(input, self.weight, self.bias)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 150777 has 14.71 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 409.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"]}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"id":"FvOy2rwViTsF"},"outputs":[],"execution_count":null}]}