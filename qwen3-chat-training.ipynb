{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"/v2/external/notebooks/gpu.ipynb","timestamp":1759308377289}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U langdetect tensorflow[and-cuda]","metadata":{"id":"Lft7MHTP-d58","executionInfo":{"status":"ok","timestamp":1759315728577,"user_tz":-570,"elapsed":88894,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0f615980-7c3b-44dc-efde-ac7aab2e274f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m901.1/981.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow[and-cuda] in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Collecting tensorflow[and-cuda]\n","  Downloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from langdetect) (1.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.6.0)\n","Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (18.1.1)\n","Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (25.0)\n","Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (75.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.1.0)\n","Requirement already satisfied: typing_extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (4.15.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (1.75.0)\n","Collecting tensorboard~=2.20.0 (from tensorflow[and-cuda])\n","  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.10.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (3.14.0)\n","Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (0.5.3)\n","Requirement already satisfied: nvidia-cublas-cu12<13.0,>=12.5.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.6.4.1)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.6.80)\n","Requirement already satisfied: nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.5.82)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.6.77)\n","Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.3.0.75 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (9.10.2.21)\n","Requirement already satisfied: nvidia-cufft-cu12<12.0,>=11.2.3.61 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12<11.0,>=10.3.6.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12<12.0,>=11.6.3.83 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12<13.0,>=12.5.1.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.5.4.2)\n","Requirement already satisfied: nvidia-nccl-cu12<3.0,>=2.25.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (2.27.3)\n","Requirement already satisfied: nvidia-nvjitlink-cu12<13.0,>=12.5.82 in /usr/local/lib/python3.12/dist-packages (from tensorflow[and-cuda]) (12.6.85)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.10.0->tensorflow[and-cuda]) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow[and-cuda]) (2025.8.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.9)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (11.3.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.20.0->tensorflow[and-cuda]) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow[and-cuda]) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.10.0->tensorflow[and-cuda]) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow[and-cuda]) (0.1.2)\n","Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorflow-2.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (620.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m944.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=351978a570dc03460621cd1352c67e8b087ce1ed4e9e9b0446bef9713b43dc9c\n","  Stored in directory: /root/.cache/pip/wheels/c1/67/88/e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n","Successfully built langdetect\n","Installing collected packages: langdetect, tensorboard, tensorflow\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.19.0\n","    Uninstalling tensorboard-2.19.0:\n","      Successfully uninstalled tensorboard-2.19.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.19.0\n","    Uninstalling tensorflow-2.19.0:\n","      Successfully uninstalled tensorflow-2.19.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tf-keras 2.19.0 requires tensorflow<2.20,>=2.19, but you have tensorflow 2.20.0 which is incompatible.\n","tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n","tensorflow-text 2.19.0 requires tensorflow<2.20,>=2.19.0, but you have tensorflow 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langdetect-1.0.9 tensorboard-2.20.0 tensorflow-2.20.0\n"]}],"execution_count":2},{"cell_type":"code","source":"%cd /content/training/\n!python generate_data.py \\\n  --num_questions 88 \\\n  --val_out_file data/traj_val.jsonl \\\n  --val_split 1.0 \\\n  --num_sequences_per_question 25 \\\n  --max_sequence_length 300 \\\n  --min_sequence_length 100 \\\n  --temperature 2.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9KT9X8e-xe6","executionInfo":{"status":"ok","timestamp":1759317845691,"user_tz":-570,"elapsed":1794977,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}},"outputId":"2d1bbc22-769e-4869-e754-38a711e81b6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n","Generating train split: 88 examples [00:00, 8171.69 examples/s]\n","Length of train_dataset:  88\n","Generating 0 training questions and 88 validation questions\n","tokenizer_config.json: 9.73kB [00:00, 40.4MB/s]\n","vocab.json: 2.78MB [00:00, 77.1MB/s]\n","merges.txt: 1.67MB [00:00, 141MB/s]\n","tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 20.6MB/s]\n","config.json: 100% 726/726 [00:00<00:00, 6.80MB/s]\n","2025-10-01 10:54:20.277571: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","model.safetensors.index.json: 25.6kB [00:00, 98.0MB/s]\n","Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n","model-00001-of-00002.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:   0% 0.00/622M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","model-00002-of-00002.safetensors:   0% 68.9k/622M [00:00<1:19:16, 131kB/s]\u001b[A\u001b[A\n","model-00001-of-00002.safetensors:   0% 853k/3.44G [00:01<1:14:24, 771kB/s]\u001b[A\n","model-00001-of-00002.safetensors:   0% 9.09M/3.44G [00:01<07:09, 8.00MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   0% 14.8M/3.44G [00:01<05:02, 11.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 27.2M/3.44G [00:01<02:28, 23.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 44.9M/3.44G [00:02<01:36, 35.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   2% 57.4M/3.44G [00:02<01:17, 43.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   2% 82.4M/3.44G [00:02<00:47, 71.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 95.1M/3.44G [00:02<00:56, 58.8MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 114M/3.44G [00:02<00:46, 71.9MB/s] \u001b[A\n","model-00001-of-00002.safetensors:   4% 137M/3.44G [00:03<00:44, 75.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   4% 150M/3.44G [00:03<00:42, 77.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 176M/3.44G [00:03<00:46, 70.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 204M/3.44G [00:04<00:37, 85.6MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:   3% 18.9M/622M [00:04<02:07, 4.73MB/s] \u001b[A\u001b[A\n","model-00001-of-00002.safetensors:   7% 235M/3.44G [00:04<00:34, 94.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 262M/3.44G [00:04<00:34, 93.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 274M/3.44G [00:04<00:33, 94.5MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 287M/3.44G [00:05<00:43, 72.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 311M/3.44G [00:05<00:41, 76.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 338M/3.44G [00:05<00:33, 92.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 351M/3.44G [00:09<03:56, 13.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 392M/3.44G [00:10<02:06, 24.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 414M/3.44G [00:10<01:46, 28.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 426M/3.44G [00:10<01:38, 30.6MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 440M/3.44G [00:10<01:31, 32.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 481M/3.44G [00:11<00:54, 54.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 495M/3.44G [00:11<00:58, 50.6MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 508M/3.44G [00:11<00:51, 57.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  16% 536M/3.44G [00:14<02:05, 23.1MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  14% 86.0M/622M [00:14<01:28, 6.09MB/s]\u001b[A\u001b[A\n","model-00001-of-00002.safetensors:  16% 549M/3.44G [00:14<02:08, 22.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  16% 562M/3.44G [00:14<01:46, 27.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 569M/3.44G [00:15<01:41, 28.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 581M/3.44G [00:20<06:33, 7.27MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 649M/3.44G [00:20<02:13, 20.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 696M/3.44G [00:20<01:22, 33.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 763M/3.44G [00:21<00:53, 49.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 842M/3.44G [00:22<00:42, 61.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 922M/3.44G [00:22<00:28, 87.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  29% 986M/3.44G [00:22<00:24, 98.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 1.02G/3.44G [00:22<00:21, 112MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 1.08G/3.44G [00:23<00:20, 115MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 1.11G/3.44G [00:23<00:18, 125MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 1.15G/3.44G [00:24<00:20, 111MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 1.22G/3.44G [00:24<00:17, 128MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 1.26G/3.44G [00:24<00:16, 130MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 1.33G/3.44G [00:25<00:15, 137MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 1.39G/3.44G [00:25<00:17, 119MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  41% 1.41G/3.44G [00:26<00:16, 120MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 1.46G/3.44G [00:26<00:14, 133MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 1.53G/3.44G [00:26<00:13, 142MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  45% 1.55G/3.44G [00:26<00:13, 140MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 1.57G/3.44G [00:27<00:12, 146MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 1.59G/3.44G [00:27<00:15, 123MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  47% 1.63G/3.44G [00:27<00:14, 129MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 1.71G/3.44G [00:28<00:17, 99.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 1.75G/3.44G [00:28<00:14, 117MB/s] \u001b[A\n","model-00001-of-00002.safetensors:  52% 1.78G/3.44G [00:29<00:17, 95.2MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  25% 153M/622M [00:29<01:31, 5.10MB/s] \u001b[A\u001b[A\n","model-00001-of-00002.safetensors:  52% 1.80G/3.44G [00:29<00:19, 84.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 1.81G/3.44G [00:29<00:18, 87.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 1.83G/3.44G [00:29<00:19, 82.7MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  35% 220M/622M [00:31<00:48, 8.28MB/s]\u001b[A\u001b[A\n","model-00001-of-00002.safetensors:  54% 1.84G/3.44G [00:31<00:41, 38.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  54% 1.86G/3.44G [00:31<00:37, 42.2MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  46% 287M/622M [00:31<00:26, 12.8MB/s]\u001b[A\u001b[A\n","\n","model-00002-of-00002.safetensors:  57% 354M/622M [00:32<00:14, 18.5MB/s]\u001b[A\u001b[A\n","model-00001-of-00002.safetensors:  54% 1.87G/3.44G [00:32<01:05, 24.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  56% 1.94G/3.44G [00:32<00:23, 63.5MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  68% 421M/622M [00:33<00:08, 24.3MB/s]\u001b[A\u001b[A\n","model-00001-of-00002.safetensors:  59% 2.02G/3.44G [00:34<00:22, 63.5MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 2.10G/3.44G [00:34<00:17, 78.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 2.13G/3.44G [00:34<00:14, 88.0MB/s]\u001b[A\n","\n","model-00002-of-00002.safetensors:  78% 488M/622M [00:35<00:05, 26.7MB/s]\u001b[A\u001b[A\n","\n","model-00002-of-00002.safetensors:  89% 555M/622M [00:37<00:02, 29.3MB/s]\u001b[A\u001b[A\n","\n","model-00002-of-00002.safetensors: 100% 622M/622M [00:37<00:00, 16.6MB/s]\n","\n","model-00001-of-00002.safetensors:  64% 2.19G/3.44G [00:37<00:30, 41.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 2.23G/3.44G [00:37<00:22, 53.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  66% 2.26G/3.44G [00:38<00:20, 57.6MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 2.32G/3.44G [00:40<00:28, 39.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 2.37G/3.44G [00:40<00:20, 51.0MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 2.42G/3.44G [00:41<00:16, 62.6MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 2.48G/3.44G [00:41<00:10, 90.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 2.51G/3.44G [00:42<00:17, 53.2MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 2.53G/3.44G [00:43<00:16, 56.7MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 2.56G/3.44G [00:43<00:15, 55.7MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 2.57G/3.44G [00:43<00:14, 59.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 2.60G/3.44G [00:43<00:11, 73.8MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 2.66G/3.44G [00:44<00:08, 95.1MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  78% 2.69G/3.44G [00:44<00:07, 98.3MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 2.80G/3.44G [00:45<00:03, 166MB/s] \u001b[A\n","model-00001-of-00002.safetensors:  83% 2.86G/3.44G [00:45<00:03, 159MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 2.93G/3.44G [00:45<00:02, 175MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 2.99G/3.44G [00:45<00:02, 200MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 3.06G/3.44G [00:46<00:01, 217MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 3.12G/3.44G [00:46<00:01, 225MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 3.15G/3.44G [00:48<00:05, 57.9MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 3.32G/3.44G [00:49<00:01, 125MB/s] \u001b[A\n","model-00001-of-00002.safetensors: 100% 3.44G/3.44G [00:55<00:00, 62.6MB/s]\n","Fetching 2 files: 100% 2/2 [00:55<00:00, 27.60s/it]\n","Loading checkpoint shards: 100% 2/2 [00:17<00:00,  8.79s/it]\n","generation_config.json: 100% 239/239 [00:00<00:00, 1.82MB/s]\n","100% 88/88 [28:18<00:00, 19.30s/it]\n","Validation dataset saved to data/traj_val.jsonl\n"]}],"execution_count":5},{"cell_type":"code","source":"%cp /content/training/train_loop.py /content/drive/MyDrive/training/","metadata":{"id":"qqx6O5rvBsJg","executionInfo":{"status":"ok","timestamp":1759318154737,"user_tz":-570,"elapsed":7,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"%cd /content/training/\n!python train_loop.py","metadata":{"id":"VOHIEBw0MLyf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759318238905,"user_tz":-570,"elapsed":43305,"user":{"displayName":"Sam Birbeck","userId":"09338901075895847279"}},"outputId":"092a9782-3727-4623-a54b-a7a50678d9d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training\n","2025-10-01 11:30:05.142995: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","Arguments saved to results/traj_chat/args.json\n","Generating train split: 2200 examples [00:00, 4542.03 examples/s]\n","Generating train split: 2200 examples [00:00, 6107.25 examples/s]\n","`torch_dtype` is deprecated! Use `dtype` instead!\n","Loading checkpoint shards: 100% 2/2 [00:15<00:00,  7.84s/it]\n","Device set to use cuda:0\n","unprompted model parameter stats:\n","trainable params: 12,845,056 || all params: 1,733,420,032 || trainable%: 0.7410\n","  0% 0/220 [00:04<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"/content/training/train_loop.py\", line 310, in <module>\n","    train_kls = do_epoch(peft_model, tokenizer,\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/content/training/train_loop.py\", line 218, in do_epoch\n","    unprompted_logits_ = peft_model(input_ids_nosys).logits\n","                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\", line 1850, in forward\n","    return self.base_model(\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py\", line 222, in forward\n","    return self.model.forward(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 940, in wrapper\n","    output = func(self, *args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 480, in forward\n","    outputs: BaseModelOutputWithPast = self.model(\n","                                       ^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\", line 1064, in wrapper\n","    outputs = func(self, *args, **kwargs)\n","              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 410, in forward\n","    hidden_states = decoder_layer(\n","                    ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\", line 94, in __call__\n","    return super().__call__(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 260, in forward\n","    hidden_states, _ = self.self_attn(\n","                       ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\", line 172, in wrapped_func\n","    return func(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\", line 200, in forward\n","    query_states = self.q_norm(self.q_proj(hidden_states).view(hidden_shape)).transpose(1, 2)\n","                               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py\", line 771, in forward\n","    result = result + lora_B(lora_A(dropout(x))) * scaling\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1773, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 1784, in _call_impl\n","    return forward_call(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n","    return F.linear(input, self.weight, self.bias)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 26.12 MiB is free. Process 150777 has 14.71 GiB memory in use. Of the allocated memory 14.19 GiB is allocated by PyTorch, and 409.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"]}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"id":"FvOy2rwViTsF"},"outputs":[],"execution_count":null}]}